Train auc:0.924649, f1:0.703812, aupr:0.809932, precision:0.88586, recall:0.583832
Dev auc:0.979844, f1:0.834725, aupr:0.940551, precision:0.961538, recall:0.737463
Test auc:0.984093, f1:0.844237, aupr:0.949038, precision:0.954225, recall:0.756983
epoch1 loss:239.71753558164428
Train auc:0.985448, f1:0.88261, aupr:0.95242, precision:0.942226, recall:0.83009
Dev auc:0.987061, f1:0.892691, aupr:0.961367, precision:0.944079, recall:0.846608
Test auc:0.989508, f1:0.903319, aupr:0.964123, precision:0.934328, recall:0.874302
epoch2 loss:104.95116339378379
Train auc:0.993674, f1:0.917684, aupr:0.975943, precision:0.951024, recall:0.886602
Dev auc:0.988648, f1:0.913043, aupr:0.967731, precision:0.963934, recall:0.867257
Test auc:0.99061, f1:0.906977, aupr:0.967567, precision:0.945455, recall:0.871508
epoch3 loss:72.74938482802403
Train auc:0.996574, f1:0.936251, aupr:0.985879, precision:0.952381, recall:0.920659
Dev auc:0.98875, f1:0.911628, aupr:0.969901, precision:0.960784, recall:0.867257
Test auc:0.990704, f1:0.90566, aupr:0.968168, precision:0.942598, recall:0.871508
epoch4 loss:54.3550916134956
Train auc:0.997639, f1:0.95103, aupr:0.9906, precision:0.961024, recall:0.941243
Dev auc:0.989344, f1:0.907956, aupr:0.97119, precision:0.963576, recall:0.858407
Test auc:0.990564, f1:0.901163, aupr:0.967827, precision:0.939394, recall:0.865922
epoch5 loss:43.434453063550585
Train auc:0.998425, f1:0.959353, aupr:0.993093, precision:0.964799, recall:0.953967
Dev auc:0.988337, f1:0.901099, aupr:0.969005, precision:0.963087, recall:0.846608
Test auc:0.990746, f1:0.896047, aupr:0.968316, precision:0.941538, recall:0.854749
epoch6 loss:36.56034789972255
Train auc:0.998388, f1:0.964494, aupr:0.993948, precision:0.968314, recall:0.960704
Dev auc:0.98937, f1:0.918836, aupr:0.970184, precision:0.955414, recall:0.884956
Test auc:0.990131, f1:0.902017, aupr:0.966995, precision:0.931548, recall:0.874302
epoch7 loss:33.323637368409784
Train auc:0.999072, f1:0.969378, aupr:0.995634, precision:0.973218, recall:0.965569
Dev auc:0.989195, f1:0.913846, aupr:0.970778, precision:0.954984, recall:0.876106
Test auc:0.990554, f1:0.902758, aupr:0.968647, precision:0.939577, recall:0.868715
epoch8 loss:28.49517960692098
Train auc:0.999264, f1:0.97408, aupr:0.99661, precision:0.977753, recall:0.970434
Dev auc:0.989284, f1:0.913505, aupr:0.969474, precision:0.940625, recall:0.887906
Test auc:0.990826, f1:0.902857, aupr:0.968041, precision:0.923977, recall:0.882682
epoch9 loss:25.042629704911562
Train auc:0.999282, f1:0.976709, aupr:0.996889, precision:0.980392, recall:0.973054
Dev auc:0.989958, f1:0.916793, aupr:0.972353, precision:0.940994, recall:0.893805
Test auc:0.990245, f1:0.904899, aupr:0.966723, precision:0.934524, recall:0.877095
epoch10 loss:23.31314914673396
Train auc:0.999574, f1:0.983286, aupr:0.99827, precision:0.986807, recall:0.97979
Dev auc:0.989616, f1:0.917541, aupr:0.972256, precision:0.932927, recall:0.902655
Test auc:0.989767, f1:0.904149, aupr:0.965079, precision:0.926686, recall:0.882682
epoch11 loss:17.496846363612097
Train auc:0.99963, f1:0.984431, aupr:0.998648, precision:0.986837, recall:0.982036
Dev auc:0.989342, f1:0.91654, aupr:0.971732, precision:0.94375, recall:0.890855
Test auc:0.9896, f1:0.904899, aupr:0.964635, precision:0.934524, recall:0.877095
epoch12 loss:15.375470770586649
Train auc:0.999675, f1:0.986301, aupr:0.998805, precision:0.989085, recall:0.983533
Dev auc:0.989244, f1:0.918182, aupr:0.971664, precision:0.943925, recall:0.893805
Test auc:0.989438, f1:0.906205, aupr:0.963909, precision:0.937313, recall:0.877095
epoch13 loss:14.23854809761185
Train auc:0.999678, f1:0.985562, aupr:0.998894, precision:0.987599, recall:0.983533
Dev auc:0.988997, f1:0.914634, aupr:0.971405, precision:0.946372, recall:0.884956
Test auc:0.988857, f1:0.903597, aupr:0.962395, precision:0.931751, recall:0.877095
epoch14 loss:13.778875864059733
Train auc:0.999679, f1:0.986116, aupr:0.998911, precision:0.988713, recall:0.983533
Dev auc:0.988972, f1:0.916031, aupr:0.971198, precision:0.949367, recall:0.884956
Test auc:0.988463, f1:0.904624, aupr:0.962056, precision:0.937126, recall:0.874302
epoch15 loss:13.465744490660793
Train auc:0.999676, f1:0.987622, aupr:0.998974, precision:0.98985, recall:0.985404
Dev auc:0.988816, f1:0.915773, aupr:0.971355, precision:0.952229, recall:0.882006
Test auc:0.988271, f1:0.901734, aupr:0.961175, precision:0.934132, recall:0.871508
epoch16 loss:12.929026111028593
Train auc:0.999693, f1:0.986122, aupr:0.999004, precision:0.988346, recall:0.983907
Dev auc:0.98853, f1:0.914634, aupr:0.97111, precision:0.946372, recall:0.884956
Test auc:0.988083, f1:0.903874, aupr:0.960638, precision:0.929204, recall:0.879888
epoch17 loss:12.802327516736694
Train auc:0.999701, f1:0.986882, aupr:0.999081, precision:0.988363, recall:0.985404
Dev auc:0.988455, f1:0.909924, aupr:0.970595, precision:0.943038, recall:0.879056
Test auc:0.987999, f1:0.901734, aupr:0.960183, precision:0.934132, recall:0.871508
epoch18 loss:12.167587138025473
Train auc:0.999713, f1:0.987437, aupr:0.999107, precision:0.989478, recall:0.985404
Dev auc:0.988523, f1:0.912977, aupr:0.970602, precision:0.946203, recall:0.882006
Test auc:0.987404, f1:0.898135, aupr:0.959241, precision:0.923304, recall:0.874302
epoch19 loss:11.961352026472847
Train auc:0.99973, f1:0.986877, aupr:0.999066, precision:0.98873, recall:0.98503
Dev auc:0.987352, f1:0.908537, aupr:0.968484, precision:0.940063, recall:0.879056
Test auc:0.988196, f1:0.900719, aupr:0.959917, precision:0.928783, recall:0.874302
epoch20 loss:12.343723906852343
Finally test result of auc:0.990245, f1:0.904899, aupr:0.966723, precision:0.934524, recall:0.877095
